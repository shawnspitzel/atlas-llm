2026-01-02 18:08:28,060 INFO    MainThread:33831 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_setup.py:_flush():80] Configure stats pid to 33831
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_setup.py:_flush():80] Loading settings from /Users/shawnspitzel/.config/wandb/settings
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_setup.py:_flush():80] Loading settings from /Users/shawnspitzel/cs336/cs326/wandb/settings
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_setup.py:_flush():80] Loading settings from environment variables
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_init.py:setup_run_log_directory():714] Logging user logs to /Users/shawnspitzel/cs336/cs326/wandb/run-20260102_180828-qrpllcw3/logs/debug.log
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to /Users/shawnspitzel/cs336/cs326/wandb/run-20260102_180828-qrpllcw3/logs/debug-internal.log
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_init.py:init():841] calling init triggers
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_init.py:init():846] wandb.init called with sweep_config: {'batch_size': 8, 'beta1': 0.9, 'beta2': 0.999, 'checkpoint_dir': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/checkpoints/model/gpt4-small-tinystories', 'checkpoint_interval': 50, 'compile': False, 'context_length': 256, 'cosine_iters': 100000, 'd_ff': 1024, 'd_model': 256, 'data_dtype': 'uint16', 'device': 'cpu', 'eval_interval': 10, 'eval_iters': 10, 'gradient_clip_norm': 1, 'learning_rate': 0.0003, 'log_interval': 10, 'max_iters': 1500, 'min_lr': 6e-05, 'num_heads': 4, 'num_layers': 4, 'optimizer': 'adamw', 'resume_from': None, 'seed': 42, 'theta': 10000, 'train_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/train/TinyStoriesV2-GPT4-train_tokens_.bin', 'val_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/val/TinyStoriesV2-GPT4-valid_val_tokens_.bin', 'vocab_size': 100000, 'warmup_iters': 2000, 'weight_decay': 0.01}
config: {'use_params': False, 'd_model': 256, 'num_heads': 4, 'd_ff': 1024, 'num_layers': 4, 'vocab_size': 100000, 'context_length': 256, 'theta': 10000.0, 'batch_size': 8, 'max_iters': 1500, 'eval_interval': 10, 'eval_iters': 10, 'log_interval': 10, 'checkpoint_interval': 50, 'seed': 42, 'optimizer': 'adamw', 'learning_rate': 0.0003, 'min_lr': 6e-05, 'weight_decay': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'gradient_clip_norm': 1.0, 'warmup_iters': 2000, 'cosine_iters': 100000, 'train_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/train/TinyStoriesV2-GPT4-train_tokens_.bin', 'val_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/val/TinyStoriesV2-GPT4-valid_val_tokens_.bin', 'data_dtype': 'uint16', 'checkpoint_dir': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/checkpoints/model/gpt4-small-tinystories', 'resume_from': 'None', 'use_wandb': False, 'wandb_project': 'cs336-assignment1', 'wandb_run_name': None, 'device': 'cpu', 'compile': False, 'profile': False, 'profile_output': 'checkpoints/profile_stats.prof', '_wandb': {}}
2026-01-02 18:08:28,061 INFO    MainThread:33831 [wandb_init.py:init():889] starting backend
2026-01-02 18:08:28,311 INFO    MainThread:33831 [wandb_init.py:init():892] sending inform_init request
2026-01-02 18:08:28,372 INFO    MainThread:33831 [wandb_init.py:init():900] backend started and connected
2026-01-02 18:08:28,374 INFO    MainThread:33831 [wandb_run.py:_config_callback():1396] config_cb None None {'batch_size': 8, 'beta1': 0.9, 'beta2': 0.999, 'checkpoint_dir': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/checkpoints/model/gpt4-small-tinystories', 'checkpoint_interval': 50, 'compile': False, 'context_length': 256, 'cosine_iters': 100000, 'd_ff': 1024, 'd_model': 256, 'data_dtype': 'uint16', 'device': 'cpu', 'eval_interval': 10, 'eval_iters': 10, 'gradient_clip_norm': 1, 'learning_rate': 0.0003, 'log_interval': 10, 'max_iters': 1500, 'min_lr': 6e-05, 'num_heads': 4, 'num_layers': 4, 'optimizer': 'adamw', 'resume_from': None, 'seed': 42, 'theta': 10000, 'train_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/train/TinyStoriesV2-GPT4-train_tokens_.bin', 'val_data': '/Users/shawnspitzel/cs336/cs326/assignment1-basics/cs336_basics/data/tokenized/tinystories/val/TinyStoriesV2-GPT4-valid_val_tokens_.bin', 'vocab_size': 100000, 'warmup_iters': 2000, 'weight_decay': 0.01}
2026-01-02 18:08:28,376 INFO    MainThread:33831 [wandb_init.py:init():970] updated telemetry
2026-01-02 18:08:28,408 INFO    MainThread:33831 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2026-01-02 18:08:28,748 INFO    MainThread:33831 [wandb_init.py:init():1041] starting run threads in backend
2026-01-02 18:08:28,845 INFO    MainThread:33831 [wandb_run.py:_console_start():2521] atexit reg
2026-01-02 18:08:28,845 INFO    MainThread:33831 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2026-01-02 18:08:28,845 INFO    MainThread:33831 [wandb_run.py:_redirect():2438] Wrapping output streams.
2026-01-02 18:08:28,845 INFO    MainThread:33831 [wandb_run.py:_redirect():2461] Redirects installed.
2026-01-02 18:08:28,851 INFO    MainThread:33831 [wandb_init.py:init():1081] run started, returning control to user process
2026-01-02 21:04:58,295 INFO    MainThread:33831 [wandb_run.py:_finish():2287] finishing run shawnspitzel-university-of-connecticut/AtlasLM-Pretrain/qrpllcw3
2026-01-02 21:04:58,403 INFO    MainThread:33831 [wandb_run.py:_atexit_cleanup():2486] got exitcode: 1
2026-01-02 21:04:58,437 INFO    MainThread:33831 [wandb_run.py:_restore():2468] restore
2026-01-02 21:04:58,442 INFO    MainThread:33831 [wandb_run.py:_restore():2474] restore done
2026-01-02 21:04:59,485 INFO    MainThread:33831 [wandb_run.py:_footer_sync_info():3862] logging synced files
