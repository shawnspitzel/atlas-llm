{
  "os": "Linux-6.6.87.1-microsoft-standard-WSL2-x86_64-with-glibc2.39",
  "python": "CPython 3.12.3",
  "startedAt": "2026-01-19T19:07:50.701529Z",
  "args": [
    "--batch_size=8",
    "--beta1=0.9",
    "--beta2=0.999",
    "--checkpoint_dir=src/checkpoints/model/gpt2",
    "--checkpoint_interval=500",
    "--compile=True",
    "--context_length=1024",
    "--cosine_iters=10000",
    "--d_ff=3072",
    "--d_model=768",
    "--data_dtype=uint16",
    "--device=cuda",
    "--eval_interval=100",
    "--eval_iters=20",
    "--gradient_clip_norm=1",
    "--learning_rate=0.00025",
    "--log_interval=10",
    "--max_iters=10000",
    "--min_lr=2.5e-05",
    "--num_heads=12",
    "--num_layers=12",
    "--optimizer=adamw",
    "--resume_from=None",
    "--seed=42",
    "--theta=10000",
    "--train_data=src/data/tokenized/owt/train/owt_train_tokens_.bin",
    "--val_data=src/data/tokenized/owt/val/owt_valid_val_tokens_.bin",
    "--vocab_size=50257",
    "--warmup_iters=375",
    "--weight_decay=0.01"
  ],
  "program": "/mnt/c/Users/kevin/CS336/atlas-llm/atlas-llm/src/training/pretrain.py",
  "codePath": "atlas-llm/src/training/pretrain.py",
  "codePathLocal": "src/training/pretrain.py",
  "git": {
    "remote": "https://github.com/shawnspitzel/atlas-llm.git",
    "commit": "938b99d74c46a6195a375395f6a0978efef3229c"
  },
  "email": "shawnspitzel@gmail.com",
  "root": "/mnt/c/Users/kevin/CS336/atlas-llm/atlas-llm",
  "host": "DESKTOP-DBTREBA",
  "executable": "/mnt/c/Users/kevin/CS336/atlas-llm/atlas-llm/.venv/bin/python",
  "cpu_count": 8,
  "cpu_count_logical": 16,
  "gpu": "NVIDIA GeForce RTX 4060 Ti",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "1081101176832",
      "used": "47025942528"
    }
  },
  "memory": {
    "total": "16729194496"
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 4060 Ti",
      "memoryTotal": "8585740288",
      "architecture": "Ada",
      "uuid": "GPU-79c3433b-e693-a218-47a0-5c430515be6c"
    }
  ],
  "cudaVersion": "12.6",
  "writerId": "5c0nwkck1bfaso7simlw216p76ajagrj"
}